{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Config"
      ],
      "metadata": {
        "id": "w3NcZOe5UxWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# Dataset name\n",
        "dataset = 'ml-1m'\n",
        "assert dataset in ['ml-1m', 'pinterest-20']\n",
        "\n",
        "# Create necessary directories\n",
        "if not os.path.exists('./data'):\n",
        "    os.makedirs('./data')\n",
        "\n",
        "# Base URL for the datasets from the GitHub repository\n",
        "base_url = 'https://raw.githubusercontent.com/hexiangnan/neural_collaborative_filtering/master/Data/'\n",
        "\n",
        "# Paths to download files\n",
        "train_rating_url = base_url + '{}.train.rating'.format(dataset)\n",
        "test_rating_url = base_url + '{}.test.rating'.format(dataset)\n",
        "test_negative_url = base_url + '{}.test.negative'.format(dataset)\n",
        "\n",
        "# Local paths where the files will be saved\n",
        "train_rating = './data/{}.train.rating'.format(dataset)\n",
        "test_rating = './data/{}.test.rating'.format(dataset)\n",
        "test_negative = './data/{}.test.negative'.format(dataset)\n",
        "\n",
        "# Function to download and save files\n",
        "def download_dataset(url, file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Downloading {file_path}...\")\n",
        "        urllib.request.urlretrieve(url, file_path)\n",
        "        print(f\"Saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"{file_path} already exists.\")\n",
        "\n",
        "# Download datasets\n",
        "download_dataset(train_rating_url, train_rating)\n",
        "download_dataset(test_rating_url, test_rating)\n",
        "download_dataset(test_negative_url, test_negative)\n",
        "\n",
        "# Paths for saving models\n",
        "model_path = './models/'\n",
        "if not os.path.exists(model_path):\n",
        "    os.makedirs(model_path)\n",
        "BPR_model_path = model_path + 'NeuMF.pth'\n",
        "\n",
        "print(\"Datasets downloaded and paths are set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXKDzWC8UpCi",
        "outputId": "92959648-05b3-4216-c8b8-27ae261913d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ./data/ml-1m.train.rating...\n",
            "Saved to ./data/ml-1m.train.rating\n",
            "Downloading ./data/ml-1m.test.rating...\n",
            "Saved to ./data/ml-1m.test.rating\n",
            "Downloading ./data/ml-1m.test.negative...\n",
            "Saved to ./data/ml-1m.test.negative\n",
            "Datasets downloaded and paths are set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Model"
      ],
      "metadata": {
        "id": "_a21G64tU1YA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class BPR(nn.Module):\n",
        "\tdef __init__(self, user_num, item_num, factor_num):\n",
        "\t\tsuper(BPR, self).__init__()\n",
        "\t\t\"\"\"\n",
        "\t\tuser_num: number of users;\n",
        "\t\titem_num: number of items;\n",
        "\t\tfactor_num: number of predictive factors.\n",
        "\t\t\"\"\"\n",
        "\t\tself.embed_user = nn.Embedding(user_num, factor_num)\n",
        "\t\tself.embed_item = nn.Embedding(item_num, factor_num)\n",
        "\n",
        "\t\tnn.init.normal_(self.embed_user.weight, std=0.01)\n",
        "\t\tnn.init.normal_(self.embed_item.weight, std=0.01)\n",
        "\n",
        "\tdef forward(self, user, item_i, item_j):\n",
        "\t\tuser = self.embed_user(user)\n",
        "\t\titem_i = self.embed_item(item_i)\n",
        "\t\titem_j = self.embed_item(item_j)\n",
        "\n",
        "\t\tprediction_i = (user * item_i).sum(dim=-1)\n",
        "\t\tprediction_j = (user * item_j).sum(dim=-1)\n",
        "\t\treturn prediction_i, prediction_j"
      ],
      "metadata": {
        "id": "wIzv51dDUtUJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data utils"
      ],
      "metadata": {
        "id": "RJKrJpI2U7gX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "\n",
        "import torch.utils.data as data\n",
        "\n",
        "def load_all(test_num=100):\n",
        "\t\"\"\" We load all the three file here to save time in each epoch. \"\"\"\n",
        "\ttrain_data = pd.read_csv(\n",
        "\t\ttrain_rating,\n",
        "\t\tsep='\\t', header=None, names=['user', 'item'],\n",
        "\t\tusecols=[0, 1], dtype={0: np.int32, 1: np.int32})\n",
        "\n",
        "\tuser_num = train_data['user'].max() + 1\n",
        "\titem_num = train_data['item'].max() + 1\n",
        "\n",
        "\ttrain_data = train_data.values.tolist()\n",
        "\n",
        "\t# load ratings as a dok matrix\n",
        "\ttrain_mat = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
        "\tfor x in train_data:\n",
        "\t\ttrain_mat[x[0], x[1]] = 1.0\n",
        "\n",
        "\ttest_data = []\n",
        "\twith open(test_negative, 'r') as fd:\n",
        "\t\tline = fd.readline()\n",
        "\t\twhile line != None and line != '':\n",
        "\t\t\tarr = line.split('\\t')\n",
        "\t\t\tu = eval(arr[0])[0]\n",
        "\t\t\ttest_data.append([u, eval(arr[0])[1]])\n",
        "\t\t\tfor i in arr[1:]:\n",
        "\t\t\t\ttest_data.append([u, int(i)])\n",
        "\t\t\tline = fd.readline()\n",
        "\treturn train_data, test_data, user_num, item_num, train_mat\n",
        "\n",
        "\n",
        "class BPRData(data.Dataset):\n",
        "\tdef __init__(self, features,\n",
        "\t\t\t\tnum_item, train_mat=None, num_ng=0, is_training=None):\n",
        "\t\tsuper(BPRData, self).__init__()\n",
        "\t\t\"\"\" Note that the labels are only useful when training, we thus\n",
        "\t\t\tadd them in the ng_sample() function.\n",
        "\t\t\"\"\"\n",
        "\t\tself.features = features\n",
        "\t\tself.num_item = num_item\n",
        "\t\tself.train_mat = train_mat\n",
        "\t\tself.num_ng = num_ng\n",
        "\t\tself.is_training = is_training\n",
        "\n",
        "\tdef ng_sample(self):\n",
        "\t\tassert self.is_training, 'no need to sampling when testing'\n",
        "\n",
        "\t\tself.features_fill = []\n",
        "\t\tfor x in self.features:\n",
        "\t\t\tu, i = x[0], x[1]\n",
        "\t\t\tfor t in range(self.num_ng):\n",
        "\t\t\t\tj = np.random.randint(self.num_item)\n",
        "\t\t\t\twhile (u, j) in self.train_mat:\n",
        "\t\t\t\t\tj = np.random.randint(self.num_item)\n",
        "\t\t\t\tself.features_fill.append([u, i, j])\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn self.num_ng * len(self.features) if \\\n",
        "\t\t\t\tself.is_training else len(self.features)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tfeatures = self.features_fill if \\\n",
        "\t\t\t\tself.is_training else self.features\n",
        "\n",
        "\t\tuser = features[idx][0]\n",
        "\t\titem_i = features[idx][1]\n",
        "\t\titem_j = features[idx][2] if \\\n",
        "\t\t\t\tself.is_training else features[idx][1]\n",
        "\t\treturn user, item_i, item_j"
      ],
      "metadata": {
        "id": "eX001A-dU3OL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Evaluate"
      ],
      "metadata": {
        "id": "Idz7DC1xVFRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def hit(gt_item, pred_items):\n",
        "    if gt_item in pred_items:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "def ndcg(gt_item, pred_items):\n",
        "    if gt_item in pred_items:\n",
        "        index = pred_items.index(gt_item)\n",
        "        return np.reciprocal(np.log2(index + 2))\n",
        "    return 0\n",
        "\n",
        "def metrics(model, test_loader, top_k, device):\n",
        "    HR, NDCG = [], []\n",
        "\n",
        "    for user, item_i, item_j in test_loader:\n",
        "        # Move tensors to the specified device (CPU or GPU)\n",
        "        user = user.to(device)\n",
        "        item_i = item_i.to(device)\n",
        "        item_j = item_j.to(device)  # item_j is not used but still moved to device\n",
        "\n",
        "        # Forward pass\n",
        "        prediction_i, prediction_j = model(user, item_i, item_j)\n",
        "\n",
        "        # Get top-k predictions\n",
        "        _, indices = torch.topk(prediction_i, top_k)\n",
        "        recommends = torch.take(item_i, indices).cpu().numpy().tolist()  # Move to CPU for numpy operations\n",
        "\n",
        "        gt_item = item_i[0].item()  # Ground truth item\n",
        "        HR.append(hit(gt_item, recommends))\n",
        "        NDCG.append(ndcg(gt_item, recommends))\n",
        "\n",
        "    return np.mean(HR), np.mean(NDCG)"
      ],
      "metadata": {
        "id": "Rq71tv3wU8Xc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Main"
      ],
      "metadata": {
        "id": "J8G2xdlsVXmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnjYqAARXfjM",
        "outputId": "bbf10bf4-b760-4c46-bbff-cf047f789126"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setups"
      ],
      "metadata": {
        "id": "HioYRRGwi22b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.backends.cudnn as cudnn\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "args = {\n",
        "    \"lr\": 0.01,\n",
        "    \"lamda\": 0.001,\n",
        "    \"batch_size\": 4096,\n",
        "    \"epochs\": 50,\n",
        "    \"top_k\": 10,\n",
        "    \"factor_num\": 32,\n",
        "    \"num_ng\": 4,\n",
        "    \"test_num_ng\": 99,\n",
        "    \"out\": True,\n",
        "    \"gpu\": \"0\"\n",
        "}\n",
        "\n",
        "# If using CUDA, set device. Otherwise, use CPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "utWbX2n8izvH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset"
      ],
      "metadata": {
        "id": "9qE-LaiHi-2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data, user_num, item_num, train_mat = load_all()\n",
        "\n",
        "# construct the train and test datasets\n",
        "train_dataset = BPRData(\n",
        "        train_data, item_num, train_mat, args[\"num_ng\"], True)\n",
        "test_dataset = BPRData(\n",
        "        test_data, item_num, train_mat, 0, False)\n",
        "train_loader = data.DataLoader(train_dataset,\n",
        "        batch_size=args[\"batch_size\"], shuffle=True, num_workers=4)\n",
        "test_loader = data.DataLoader(test_dataset,\n",
        "        batch_size=args[\"test_num_ng\"] + 1, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BowqYfkqjA2h",
        "outputId": "6ae12028-9ea6-407d-88a5-568392fcacfe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ],
      "metadata": {
        "id": "fGm1a50KjJUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BPR(user_num, item_num, args[\"factor_num\"])\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(\n",
        "            model.parameters(), lr=args[\"lr\"], weight_decay=args[\"lamda\"])\n",
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "id": "ZeG5WKpGjMMt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "0kQelFmXjUgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count, best_hr = 0, 0\n",
        "for epoch in range(args[\"epochs\"]):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    train_loader.dataset.ng_sample()\n",
        "\n",
        "    for user, item_i, item_j in train_loader:\n",
        "        user = user.to(device)\n",
        "        item_i = item_i.to(device)\n",
        "        item_j = item_j.to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        prediction_i, prediction_j = model(user, item_i, item_j)\n",
        "        loss = - (prediction_i - prediction_j).sigmoid().log().sum()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        writer.add_scalar('data/loss', loss.item(), count)\n",
        "        count += 1\n",
        "\n",
        "    model.eval()\n",
        "    HR, NDCG = metrics(model, test_loader, top_k=args[\"top_k\"], device=device)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(\"The time elapsed of epoch {:03d}\".format(epoch) + \" is: \" +\n",
        "          time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
        "    print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n",
        "\n",
        "    if HR > best_hr:\n",
        "        best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n",
        "        if args[\"out\"]:\n",
        "            if not os.path.exists(model_path):\n",
        "                os.mkdir(model_path)\n",
        "            torch.save(model, f'{model_path}/BPR.pt')\n",
        "\n",
        "print(\"End. Best epoch {:03d}: HR = {:.3f}, \\\n",
        "    NDCG = {:.3f}\".format(best_epoch, best_hr, best_ndcg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvL3VdKYjVng",
        "outputId": "79c5266e-a025-4b59-bc01-9d0229a6daf9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time elapsed of epoch 000 is: 00:00:37\n",
            "HR: 0.440\tNDCG: 0.246\n",
            "The time elapsed of epoch 001 is: 00:00:39\n",
            "HR: 0.454\tNDCG: 0.252\n",
            "The time elapsed of epoch 002 is: 00:00:38\n",
            "HR: 0.487\tNDCG: 0.274\n",
            "The time elapsed of epoch 003 is: 00:00:37\n",
            "HR: 0.524\tNDCG: 0.294\n",
            "The time elapsed of epoch 004 is: 00:00:36\n",
            "HR: 0.561\tNDCG: 0.313\n",
            "The time elapsed of epoch 005 is: 00:00:37\n",
            "HR: 0.583\tNDCG: 0.328\n",
            "The time elapsed of epoch 006 is: 00:00:37\n",
            "HR: 0.601\tNDCG: 0.341\n",
            "The time elapsed of epoch 007 is: 00:00:39\n",
            "HR: 0.623\tNDCG: 0.355\n",
            "The time elapsed of epoch 008 is: 00:00:37\n",
            "HR: 0.631\tNDCG: 0.363\n",
            "The time elapsed of epoch 009 is: 00:00:39\n",
            "HR: 0.644\tNDCG: 0.371\n",
            "The time elapsed of epoch 010 is: 00:00:37\n",
            "HR: 0.651\tNDCG: 0.379\n",
            "The time elapsed of epoch 011 is: 00:00:39\n",
            "HR: 0.660\tNDCG: 0.384\n",
            "The time elapsed of epoch 012 is: 00:00:37\n",
            "HR: 0.668\tNDCG: 0.389\n",
            "The time elapsed of epoch 013 is: 00:00:39\n",
            "HR: 0.673\tNDCG: 0.394\n",
            "The time elapsed of epoch 014 is: 00:00:39\n",
            "HR: 0.676\tNDCG: 0.396\n",
            "The time elapsed of epoch 015 is: 00:00:37\n",
            "HR: 0.681\tNDCG: 0.400\n",
            "The time elapsed of epoch 016 is: 00:00:38\n",
            "HR: 0.681\tNDCG: 0.402\n",
            "The time elapsed of epoch 017 is: 00:00:37\n",
            "HR: 0.687\tNDCG: 0.405\n",
            "The time elapsed of epoch 018 is: 00:00:37\n",
            "HR: 0.688\tNDCG: 0.406\n",
            "The time elapsed of epoch 019 is: 00:00:40\n",
            "HR: 0.691\tNDCG: 0.408\n",
            "The time elapsed of epoch 020 is: 00:00:37\n",
            "HR: 0.692\tNDCG: 0.411\n",
            "The time elapsed of epoch 021 is: 00:00:36\n",
            "HR: 0.692\tNDCG: 0.411\n",
            "The time elapsed of epoch 022 is: 00:00:37\n",
            "HR: 0.694\tNDCG: 0.412\n",
            "The time elapsed of epoch 023 is: 00:00:36\n",
            "HR: 0.693\tNDCG: 0.413\n",
            "The time elapsed of epoch 024 is: 00:00:38\n",
            "HR: 0.694\tNDCG: 0.415\n",
            "The time elapsed of epoch 025 is: 00:00:39\n",
            "HR: 0.699\tNDCG: 0.415\n",
            "The time elapsed of epoch 026 is: 00:00:37\n",
            "HR: 0.696\tNDCG: 0.416\n",
            "The time elapsed of epoch 027 is: 00:00:39\n",
            "HR: 0.700\tNDCG: 0.418\n",
            "The time elapsed of epoch 028 is: 00:00:38\n",
            "HR: 0.699\tNDCG: 0.416\n",
            "The time elapsed of epoch 029 is: 00:00:37\n",
            "HR: 0.700\tNDCG: 0.417\n",
            "The time elapsed of epoch 030 is: 00:00:39\n",
            "HR: 0.699\tNDCG: 0.417\n",
            "The time elapsed of epoch 031 is: 00:00:37\n",
            "HR: 0.695\tNDCG: 0.418\n",
            "The time elapsed of epoch 032 is: 00:00:37\n",
            "HR: 0.697\tNDCG: 0.421\n",
            "The time elapsed of epoch 033 is: 00:00:37\n",
            "HR: 0.698\tNDCG: 0.420\n",
            "The time elapsed of epoch 034 is: 00:00:36\n",
            "HR: 0.699\tNDCG: 0.420\n",
            "The time elapsed of epoch 035 is: 00:00:36\n",
            "HR: 0.700\tNDCG: 0.422\n",
            "The time elapsed of epoch 036 is: 00:00:39\n",
            "HR: 0.700\tNDCG: 0.421\n",
            "The time elapsed of epoch 037 is: 00:00:37\n",
            "HR: 0.703\tNDCG: 0.420\n",
            "The time elapsed of epoch 038 is: 00:00:36\n",
            "HR: 0.702\tNDCG: 0.419\n",
            "The time elapsed of epoch 039 is: 00:00:37\n",
            "HR: 0.697\tNDCG: 0.419\n",
            "The time elapsed of epoch 040 is: 00:00:37\n",
            "HR: 0.700\tNDCG: 0.421\n",
            "The time elapsed of epoch 041 is: 00:00:37\n",
            "HR: 0.698\tNDCG: 0.421\n",
            "The time elapsed of epoch 042 is: 00:00:37\n",
            "HR: 0.697\tNDCG: 0.422\n",
            "The time elapsed of epoch 043 is: 00:00:37\n",
            "HR: 0.696\tNDCG: 0.422\n",
            "The time elapsed of epoch 044 is: 00:00:36\n",
            "HR: 0.698\tNDCG: 0.423\n",
            "The time elapsed of epoch 045 is: 00:01:00\n",
            "HR: 0.698\tNDCG: 0.421\n",
            "The time elapsed of epoch 046 is: 00:00:44\n",
            "HR: 0.695\tNDCG: 0.421\n",
            "The time elapsed of epoch 047 is: 00:00:36\n",
            "HR: 0.696\tNDCG: 0.421\n",
            "The time elapsed of epoch 048 is: 00:00:37\n",
            "HR: 0.695\tNDCG: 0.422\n",
            "The time elapsed of epoch 049 is: 00:00:36\n",
            "HR: 0.695\tNDCG: 0.421\n",
            "End. Best epoch 037: HR = 0.703,     NDCG = 0.420\n"
          ]
        }
      ]
    }
  ]
}